{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1524a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ee0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        try:\n",
    "            db = create_engine('postgresql+psycopg2://'+db_user+':'+db_pw+'@'+host+'/'+default_db, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(sqlcmd, args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141738fb",
   "metadata": {},
   "source": [
    "Connect SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4f0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ca19f",
   "metadata": {},
   "source": [
    "Open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52cb1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = gpd.read_file('SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp')\n",
    "businesses = pd.read_csv('Businesses.csv')\n",
    "stops = pd.read_csv('Stops.txt')\n",
    "polls = pd.read_csv('PollingPlaces2019.csv')\n",
    "school_future = gpd.read_file('catchments/catchments_future.shp')\n",
    "school_primary = gpd.read_file('catchments/catchments_primary.shp')\n",
    "school_secondary = gpd.read_file('catchments/catchments_secondary.shp')\n",
    "population = pd.read_csv('Population.csv')\n",
    "income = pd.read_csv('Income.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcd38a",
   "metadata": {},
   "source": [
    "Ensure every row in geometry is represented as multipolygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\n",
    "srid = 4326\n",
    "regions.dropna(inplace=True)\n",
    "regions['geom'] = regions['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))  # applying the function\n",
    "regions = regions.drop(columns=\"geometry\")  # deleting the old copy\n",
    "\n",
    "school_future['geom'] = school_future['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_future = school_future.drop(columns=\"geometry\")\n",
    "\n",
    "school_primary['geom'] = school_primary['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_primary = school_primary.drop(columns=\"geometry\")\n",
    "\n",
    "school_secondary['geom'] = school_secondary['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_secondary = school_secondary.drop(columns=\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf458e2",
   "metadata": {},
   "source": [
    "Create a column 'geom' for stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e158113",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['geom'] = gpd.points_from_xy(stops.stop_lon, stops.stop_lat)\n",
    "stops = stops.drop(columns=['stop_lat', 'stop_lon'])\n",
    "stops['geom'] = stops['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee2bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "polls.dropna(subset=['the_geom'], inplace=True)\n",
    "polls['geom'] = gpd.points_from_xy(polls.longitude, polls.latitude)\n",
    "polls['geom'] = polls['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))\n",
    "polls.drop(columns=['the_geom'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92613098",
   "metadata": {},
   "source": [
    "Rename columns because some of the column names start with number or is uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dba7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_converter_regions(col_names):\n",
    "    col_dict = {}\n",
    "    for c in col_names:\n",
    "        new_c = c.lower() #convert every column name to lowercase\n",
    "        if new_c[-2:] == '21': # if column names end with 21, remove it\n",
    "            new_c = new_c[:-2]\n",
    "        if new_c == 'loci_uri':\n",
    "            new_c = 'url'\n",
    "        col_dict[c] = new_c\n",
    "    return col_dict\n",
    "\n",
    "def col_converter_school(col_names):\n",
    "    col_dict = {}\n",
    "    for c in col_names:\n",
    "        col_dict[c] = c.lower()\n",
    "    return col_dict\n",
    "\n",
    "col_names = regions.columns.values.tolist()\n",
    "regions = regions.rename(columns=col_converter_regions(col_names))\n",
    "\n",
    "col_names = school_future.columns.tolist()\n",
    "school_future = school_future.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "col_names = school_primary.columns.tolist()\n",
    "school_primary = school_primary.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "col_names = school_secondary.columns.tolist()\n",
    "school_secondary = school_secondary.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "businesses = businesses.rename(columns={'0_to_50k_businesses':'b_0_to_50k', '50k_to_200k_businesses':'b_50k_to_200k', '200k_to_2m_businesses':'b_200k_to_2m'})\n",
    "businesses = businesses.rename(columns={'2m_to_5m_businesses':'b_2m_to_5m', '5m_to_10m_businesses':'b_5m_to_10m', '10m_or_more_businesses':'b_10m_or_more'})\n",
    "\n",
    "population = population.rename(columns={'0-4_people':'p_0_to_4', '5-9_people':'p_5_to_9', '10-14_people':'p_10_to_14', '15-19_people':'p_15_to_19'})\n",
    "population = population.rename(columns={'20-24_people':'p_20_to_24', '25-29_people':'p_25_to_29', '30-34_people':'p_30_to_34', '35-39_people':'p_35_to_39'})\n",
    "population = population.rename(columns={'40-44_people':'p_40_to_44', '45-49_people':'p_45_to_49', '50-54_people':'p_50_to_54', '55-59_people':'p_55_to_59'})\n",
    "population = population.rename(columns={'60-64_people':'p_60_to_64', '65-69_people':'p_65_to_69', '70-74_people':'p_70_to_74', '75-79_people':'p_75_to_79'})\n",
    "population = population.rename(columns={'80-84_people':'p_80_to_84', '85-and-over_people':'p_85_and_over'})\n",
    "\n",
    "polls = polls.rename(columns={'FID':'fid'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eea7c6",
   "metadata": {},
   "source": [
    "Replace some NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b36aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.replace('np', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac9243",
   "metadata": {},
   "source": [
    "Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dcdf12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.CursorResult at 0x1437c2b30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS regions cascade;\n",
    "CREATE TABLE regions (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    chg_flag CHAR,\n",
    "    chg_lbl VARCHAR(20),\n",
    "    sa3_code VARCHAR(5),\n",
    "    sa3_name VARCHAR(100),\n",
    "    sa4_code VARCHAR(3),\n",
    "    sa4_name VARCHAR(100),\n",
    "    gcc_code VARCHAR(5),\n",
    "    gcc_name VARCHAR(100),\n",
    "    ste_code CHAR,\n",
    "    ste_name VARCHAR(100),\n",
    "    aus_code VARCHAR(3),\n",
    "    aus_name VARCHAR(100),\n",
    "    areasqkm FLOAT,\n",
    "    url VARCHAR(100),\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS businesses;\n",
    "CREATE TABLE businesses (\n",
    "    industry_code CHAR, \n",
    "    industry_name VARCHAR(100),\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    b_0_to_50k INTEGER,\n",
    "    b_50k_to_200k INTEGER,\n",
    "    b_200k_to_2m INTEGER,\n",
    "    b_2m_to_5m INTEGER,\n",
    "    b_5m_to_10m INTEGER,\n",
    "    b_10m_or_more INTEGER,\n",
    "    total_businesses INTEGER\n",
    ");\n",
    "\"\"\"))\n",
    "#b_0_to_50k is the number of businesses' income < 50k\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS stops;\n",
    "CREATE TABLE stops (\n",
    "    stop_id VARCHAR(10),\n",
    "    stop_code VARCHAR(10),\n",
    "    stop_name VARCHAR(100),\n",
    "    location_type FLOAT,\n",
    "    parent_station VARCHAR(10),\n",
    "    wheelchair_boarding CHAR,\n",
    "    platform_code VARCHAR(10),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS polls;\n",
    "CREATE TABLE polls (\n",
    "    fid VARCHAR(100),\n",
    "    state VARCHAR(3),\n",
    "    division_id INTEGER,\n",
    "    division_name VARCHAR(100),\n",
    "    polling_place_id INTEGER,\n",
    "    polling_place_type_id INTEGER,\n",
    "    polling_place_name VARCHAR(100),\n",
    "    premises_name VARCHAR(100),\n",
    "    premises_address_1 VARCHAR(100),\n",
    "    premises_address_2 VARCHAR(100),\n",
    "    premises_address_3 VARCHAR(100),\n",
    "    premises_suburb VARCHAR(100),\n",
    "    premises_state_abbreviation VARCHAR(3),\n",
    "    premises_post_code INTEGER,\n",
    "    latitude FLOAT,\n",
    "    longitude FLOAT,\n",
    "    geom GEOMETRY(POINT,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_future;\n",
    "CREATE TABLE school_future (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart INTEGER,\n",
    "    year1 INTEGER,\n",
    "    year2 INTEGER,\n",
    "    year3 INTEGER,\n",
    "    year4 INTEGER,\n",
    "    year5 INTEGER,\n",
    "    year6 INTEGER,\n",
    "    year7 INTEGER,\n",
    "    year8 INTEGER,\n",
    "    year9 INTEGER,\n",
    "    year10 INTEGER,\n",
    "    year11 INTEGER,\n",
    "    year12 INTEGER,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_primary;\n",
    "CREATE TABLE school_primary (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart CHAR,\n",
    "    year1 CHAR,\n",
    "    year2 CHAR,\n",
    "    year3 CHAR,\n",
    "    year4 CHAR,\n",
    "    year5 CHAR,\n",
    "    year6 CHAR,\n",
    "    year7 CHAR,\n",
    "    year8 CHAR,\n",
    "    year9 CHAR,\n",
    "    year10 CHAR,\n",
    "    year11 CHAR,\n",
    "    year12 CHAR,\n",
    "    priority CHAR,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_secondary;\n",
    "CREATE TABLE school_secondary (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart CHAR,\n",
    "    year1 CHAR,\n",
    "    year2 CHAR,\n",
    "    year3 CHAR,\n",
    "    year4 CHAR,\n",
    "    year5 CHAR,\n",
    "    year6 CHAR,\n",
    "    year7 CHAR,\n",
    "    year8 CHAR,\n",
    "    year9 CHAR,\n",
    "    year10 CHAR,\n",
    "    year11 CHAR,\n",
    "    year12 CHAR,\n",
    "    priority CHAR,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS population;\n",
    "CREATE TABLE population (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    p_0_to_4 INTEGER,\n",
    "    p_5_to_9 INTEGER,\n",
    "    p_10_to_14 INTEGER,\n",
    "    p_15_to_19 INTEGER,\n",
    "    p_20_to_24 INTEGER,\n",
    "    p_25_to_29 INTEGER,\n",
    "    p_30_to_34 INTEGER,\n",
    "    p_35_to_39 INTEGER,\n",
    "    p_40_to_44 INTEGER,\n",
    "    p_45_to_49 INTEGER,\n",
    "    p_50_to_54 INTEGER,\n",
    "    p_55_to_59 INTEGER,\n",
    "    p_60_to_64 INTEGER,\n",
    "    p_65_to_69 INTEGER,\n",
    "    p_70_to_74 INTEGER,\n",
    "    p_75_to_79 INTEGER,\n",
    "    p_80_to_84 INTEGER,\n",
    "    p_85_and_over INTEGER,\n",
    "    total_people INTEGER\n",
    ");\n",
    "\"\"\"))\n",
    "#p_0_to_4 is the number of people age from 0 to 4\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS income;\n",
    "CREATE TABLE income (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    earners INTEGER,\n",
    "    median_age INTEGER,\n",
    "    median_income INTEGER,\n",
    "    mean_income INTEGER\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c973e0f",
   "metadata": {},
   "source": [
    "Importing dataframes to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "376a0842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions.to_sql('regions', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "businesses.to_sql('businesses', conn, if_exists='append', index=False)\n",
    "stops.to_sql('stops', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "polls.to_sql('polls', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "school_future.to_sql('school_future', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "school_primary.to_sql('school_primary', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "school_secondary.to_sql('school_secondary', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "population.to_sql('population', conn, if_exists='append', index=False)\n",
    "income.to_sql('income', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab308fd",
   "metadata": {},
   "source": [
    "Get investigatable regions, young people per region, total people per region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb87a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, (p_0_to_4 + p_5_to_9 + p_10_to_14 + p_15_to_19) as young_people, total_people\n",
    "    FROM population\n",
    "\"\"\"))\n",
    "\n",
    "regions_arr = []\n",
    "region_to_young = dict()\n",
    "region_to_people = dict()\n",
    "for i, row in result.iterrows():\n",
    "    name, young, total = row.values\n",
    "    if young > 100 and total > 100:\n",
    "        regions_arr.append(name)\n",
    "        try:\n",
    "            young = int(young)\n",
    "            if young != 0:\n",
    "                region_to_young[name] = young\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "        try:\n",
    "            total = int(total)\n",
    "            if total != 0:\n",
    "                region_to_people[name] = total\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "\n",
    "print(len(regions_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e954aa",
   "metadata": {},
   "source": [
    "Retail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "649391a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, total_businesses\n",
    "    FROM businesses\n",
    "    WHERE industry_name = 'Retail Trade'\n",
    "    ORDER BY total_businesses DESC\n",
    "\"\"\"))\n",
    "\n",
    "retail_dict = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    name, total = row.values\n",
    "    total = int(total)\n",
    "    retail_dict[name] = total\n",
    "\n",
    "retail_per_thousand = dict.fromkeys(regions_arr, 0)\n",
    "for key in retail_dict.keys():\n",
    "    try:\n",
    "        num = (retail_dict[key] / region_to_people[key])*1000\n",
    "        retail_per_thousand[key] = num\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "retail_per_thousand = dict(sorted(retail_per_thousand.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "zscores = zscore(list(retail_per_thousand.values()))\n",
    "retail_zscores = dict(zip(retail_per_thousand.keys(), zscores))\n",
    "\n",
    "print(len(retail_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f8dc5",
   "metadata": {},
   "source": [
    "Health:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cc7c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, total_businesses\n",
    "    FROM businesses\n",
    "    WHERE industry_name = 'Health Care and Social Assistance'\n",
    "    ORDER BY total_businesses DESC\n",
    "\"\"\"))\n",
    "\n",
    "health_dict = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    name, total = row.values\n",
    "    total = int(total)\n",
    "    health_dict[name] = total\n",
    "\n",
    "health_per_thousand = dict()\n",
    "for key in health_dict.keys():\n",
    "    try:\n",
    "        num = (health_dict[key] / region_to_people[key])*1000\n",
    "        health_per_thousand[key] = num\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "health_per_thousand = dict(sorted(health_per_thousand.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "zscores = zscore(list(health_per_thousand.values()))\n",
    "health_zscores = dict(zip(health_per_thousand.keys(), zscores))\n",
    "    \n",
    "print(len(health_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3be005",
   "metadata": {},
   "source": [
    "Index regions and stops for fast JOIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d58898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_regions;\n",
    "    CREATE INDEX geom_idx_regions ON regions USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_stops;\n",
    "    CREATE INDEX geom_idx_stops ON regions USING GIST(geom);\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39bfeb",
   "metadata": {},
   "source": [
    "Stops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "027fccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN stops s ON ST_Contains(r.geom, s.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "stops_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        stops_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(stops_per_region.values()))\n",
    "stops_zscores = dict(zip(stops_per_region.keys(), zscores))\n",
    "\n",
    "print(len(stops_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b352c",
   "metadata": {},
   "source": [
    "Polls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2857b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN polls p ON ST_Contains(r.geom, p.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "polls_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        polls_per_region[region] = count\n",
    "\n",
    "zscores = zscore(list(polls_per_region.values()))\n",
    "polls_zscores = dict(zip(polls_per_region.keys(), zscores))\n",
    "\n",
    "print(len(polls_zscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_primary;\n",
    "    CREATE INDEX geom_idx_primary ON school_primary USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_secondary;\n",
    "    CREATE INDEX geom_idx_secondary ON school_secondary USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_future;\n",
    "    CREATE INDEX geom_idx_future ON school_future USING GIST(geom);\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ac8ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_primary s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "schools_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] = count\n",
    "\n",
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_secondary s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] += count\n",
    "\n",
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_future s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] += count\n",
    "        \n",
    "zscores = zscore(list(schools_per_region.values()))\n",
    "schools_zscores = dict(zip(schools_per_region.keys(), zscores))\n",
    "\n",
    "print(len(schools_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd8198",
   "metadata": {},
   "source": [
    "Calculate Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e508d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "for region in regions_arr:\n",
    "    sum = 0\n",
    "    try:\n",
    "        sum += retail_zscores.get(region)\n",
    "        sum += health_zscores.get(region)\n",
    "        sum += stops_zscores.get(region)\n",
    "        sum += polls_zscores.get(region)\n",
    "        sum += schools_zscores.get(region)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    scores[region] = 1 / (1 + math.exp(-sum))\n",
    "\n",
    "print(len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d29ec",
   "metadata": {},
   "source": [
    "Car crash in NSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e23c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = pd.read_excel('car_crash.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3cb3",
   "metadata": {},
   "source": [
    "Kepp specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56e4513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = crash[['Degree of crash', 'Year of crash', 'Month of crash', 'Day of week of crash', 'Latitude', 'Longitude', 'Weather']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d0e03",
   "metadata": {},
   "source": [
    "Create geom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f184e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash.dropna(inplace=True)\n",
    "crash['geom'] = gpd.points_from_xy(crash.Longitude, crash.Latitude)\n",
    "crash = crash.drop(columns=['Longitude', 'Latitude'])\n",
    "crash['geom'] = crash['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19693bc3",
   "metadata": {},
   "source": [
    "Convert columns to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a31a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "for c in crash.columns:\n",
    "    col_dict[c] = c.lower()\n",
    "    keyword = c.split(' ')[0]\n",
    "    if keyword in ['Degree', 'Year', 'Month', 'Day']:\n",
    "        col_dict[c] = keyword.lower()\n",
    "crash.rename(columns=col_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce94e2b",
   "metadata": {},
   "source": [
    "Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22acb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS crash;\n",
    "CREATE TABLE crash (\n",
    "    degree VARCHAR(100),\n",
    "    year INT,\n",
    "    month VARCHAR(20),\n",
    "    day VARCHAR(15),\n",
    "    weather VARCHAR(50),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c90a8e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash.to_sql('crash', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1529df48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN crash c ON ST_Contains(r.geom, c.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count(*) DESC\n",
    "\"\"\"))\n",
    "\n",
    "crash_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        crash_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(crash_per_region.values()))\n",
    "crash_zscores = dict(zip(crash_per_region.keys(), zscores))\n",
    "print(len(crash_zscores))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83975975",
   "metadata": {},
   "source": [
    "Crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb0de58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = pd.read_csv(\"crime_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427d590",
   "metadata": {},
   "source": [
    "Keep specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d204a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = crime[['bcsrgrp', 'locsurb', 'locpcode', 'bcsrgclat', 'bcsrgclng', 'incyear', 'incmonth', 'incday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75ab83",
   "metadata": {},
   "source": [
    "Create geom column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19dc7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.dropna(subset=['bcsrgclat', 'bcsrgclng'], inplace=True)\n",
    "crime['geom'] = gpd.points_from_xy(crime.bcsrgclng, crime.bcsrgclat)\n",
    "crime = crime.drop(columns=['bcsrgclng', 'bcsrgclat'])\n",
    "crime['geom'] = crime['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309dc643",
   "metadata": {},
   "source": [
    "Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14c7febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS crime;\n",
    "CREATE TABLE crime (\n",
    "    bcsrgrp VARCHAR(100),\n",
    "    locsurb VARCHAR(100), \n",
    "    locpcode INT,\n",
    "    incyear INT,\n",
    "    incmonth VARCHAR(15),\n",
    "    incday VARCHAR(10),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5cc15ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime.to_sql('crime', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02167ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN crime c ON ST_Contains(r.geom, c.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count(*) DESC\n",
    "\"\"\"))\n",
    "\n",
    "crime_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        crime_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(crime_per_region.values()))\n",
    "crime_zscores = dict(zip(crime_per_region.keys(), zscores))\n",
    "print(len(crime_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3ea42",
   "metadata": {},
   "source": [
    "New Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62b797f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "new_scores = dict()\n",
    "for region in regions_arr:\n",
    "    sum = 0\n",
    "    try:\n",
    "        sum += retail_zscores.get(region)\n",
    "        sum += health_zscores.get(region)\n",
    "        sum += stops_zscores.get(region)\n",
    "        sum += polls_zscores.get(region)\n",
    "        sum += schools_zscores.get(region)\n",
    "        sum -= crash_zscores.get(region)\n",
    "        sum -= crime_zscores.get(region)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    new_scores[region] = 1 / (1 + math.exp(-sum))\n",
    "\n",
    "print(len(new_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7219c",
   "metadata": {},
   "source": [
    "Graph for New Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27cd23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a5c4576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sorted_scores.items(), columns=[\"SA2 Regions\", \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b07d5f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['SA2 Region', 'Retail Z-score', 'Health Z-score', 'Stops Z-score', 'Schools Z-score', 'Crashes Z-score', 'Crime Z-score', 'Score'] but received: SA2 Regions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39;49mbar(df, x\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSA2 Regions\u001b[39;49m\u001b[39m\"\u001b[39;49m, y\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m\"\u001b[39;49m, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m fig\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_chart_types.py:373\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(data_frame, x, y, color, pattern_shape, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, text, base, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, pattern_shape_sequence, pattern_shape_map, range_color, color_continuous_midpoint, opacity, orientation, barmode, log_x, log_y, range_x, range_y, text_auto, title, template, width, height)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbar\u001b[39m(\n\u001b[1;32m    326\u001b[0m     data_frame\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    368\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m go\u001b[39m.\u001b[39mFigure:\n\u001b[1;32m    369\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m    In a bar plot, each row of `data_frame` is represented as a rectangular\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m    mark.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     \u001b[39mreturn\u001b[39;00m make_figure(\n\u001b[1;32m    374\u001b[0m         args\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m(),\n\u001b[1;32m    375\u001b[0m         constructor\u001b[39m=\u001b[39;49mgo\u001b[39m.\u001b[39;49mBar,\n\u001b[1;32m    376\u001b[0m         trace_patch\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(textposition\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    377\u001b[0m         layout_patch\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(barmode\u001b[39m=\u001b[39;49mbarmode),\n\u001b[1;32m    378\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1996\u001b[0m, in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   1993\u001b[0m layout_patch \u001b[39m=\u001b[39m layout_patch \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m   1994\u001b[0m apply_default_cascade(args)\n\u001b[0;32m-> 1996\u001b[0m args \u001b[39m=\u001b[39m build_dataframe(args, constructor)\n\u001b[1;32m   1997\u001b[0m \u001b[39mif\u001b[39;00m constructor \u001b[39min\u001b[39;00m [go\u001b[39m.\u001b[39mTreemap, go\u001b[39m.\u001b[39mSunburst, go\u001b[39m.\u001b[39mIcicle] \u001b[39mand\u001b[39;00m args[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1998\u001b[0m     args \u001b[39m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1409\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[0;34m(args, constructor)\u001b[0m\n\u001b[1;32m   1406\u001b[0m     args[\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m \u001b[39m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[0;32m-> 1409\u001b[0m df_output, wide_id_vars \u001b[39m=\u001b[39m process_args_into_dataframe(\n\u001b[1;32m   1410\u001b[0m     args, wide_mode, var_name, value_name\n\u001b[1;32m   1411\u001b[0m )\n\u001b[1;32m   1413\u001b[0m \u001b[39m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[39m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[39m# df_output\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m count_name \u001b[39m=\u001b[39m _escape_col_name(df_output, \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1208\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[0;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[39mif\u001b[39;00m argument \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1207\u001b[0m             err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m   1209\u001b[0m \u001b[39melif\u001b[39;00m length \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df_input[argument]) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m   1210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1211\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll arguments should have the same length. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe length of column argument `df[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]` is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, whereas the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         )\n\u001b[1;32m   1220\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['SA2 Region', 'Retail Z-score', 'Health Z-score', 'Stops Z-score', 'Schools Z-score', 'Crashes Z-score', 'Crime Z-score', 'Score'] but received: SA2 Regions"
     ]
    }
   ],
   "source": [
    "fig = px.bar(df, x=\"SA2 Regions\", y=\"Score\", color='Score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b293e3",
   "metadata": {},
   "source": [
    "Income vs. Score Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "526948b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         x\u001b[39m.\u001b[39mappend(income_dict\u001b[39m.\u001b[39mget(region))\n\u001b[1;32m     17\u001b[0m         y\u001b[39m.\u001b[39mappend(new_scores\u001b[39m.\u001b[39mget(region))\n\u001b[0;32m---> 19\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39mAverage income\u001b[39;49m\u001b[39m'\u001b[39;49m:x, \u001b[39m'\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m'\u001b[39;49m:y, \u001b[39m'\u001b[39;49m\u001b[39mRegion\u001b[39;49m\u001b[39m'\u001b[39;49m:regions})\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/construction.py:123\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    122\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     arrays \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[1;32m    124\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/construction.py:617\u001b[0m, in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    614\u001b[0m             val \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(val)\n\u001b[1;32m    615\u001b[0m         val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[0;32m--> 617\u001b[0m     val \u001b[39m=\u001b[39m sanitize_array(\n\u001b[1;32m    618\u001b[0m         val, index, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, raise_cast_failure\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    619\u001b[0m     )\n\u001b[1;32m    620\u001b[0m     com\u001b[39m.\u001b[39mrequire_length_match(val, index)\n\u001b[1;32m    622\u001b[0m homogenized\u001b[39m.\u001b[39mappend(val)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/construction.py:642\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 642\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_convert_platform(data)\n\u001b[1;32m    643\u001b[0m     \u001b[39mif\u001b[39;00m subarr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    644\u001b[0m         subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:135\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj:\n\u001b[1;32m    134\u001b[0m     arr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 135\u001b[0m     arr \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmaybe_convert_objects(arr)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2449\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT sa2_name, median_income\n",
    "    FROM income\n",
    "    ORDER BY mean_income DESC\n",
    "\"\"\"))\n",
    "income_dict = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, income = row.values\n",
    "    if region in regions_arr:\n",
    "        income_dict[region] = income\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for region in income_dict.keys():\n",
    "    if income_dict.get(region) != 0:\n",
    "        x.append(income_dict.get(region))\n",
    "        y.append(new_scores.get(region))\n",
    "\n",
    "df = pd.DataFrame({'Average income':x, 'Score':y, 'Region':regions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "831614d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['SA2 Regions', 'Score'] but received: Average income",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39;49mscatter(df, x\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAverage income\u001b[39;49m\u001b[39m'\u001b[39;49m, y\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m'\u001b[39;49m, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAverage income\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m fig\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_chart_types.py:66\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(data_frame, x, y, color, symbol, size, hover_name, hover_data, custom_data, text, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, orientation, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, symbol_sequence, symbol_map, opacity, size_max, marginal_x, marginal_y, trendline, trendline_options, trendline_color_override, trendline_scope, log_x, log_y, range_x, range_y, render_mode, title, template, width, height)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m     13\u001b[0m     data_frame\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m go\u001b[39m.\u001b[39mFigure:\n\u001b[1;32m     62\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m    In a scatter plot, each row of `data_frame` is represented by a symbol\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    mark in 2D space.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m make_figure(args\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m(), constructor\u001b[39m=\u001b[39;49mgo\u001b[39m.\u001b[39;49mScatter)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1996\u001b[0m, in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   1993\u001b[0m layout_patch \u001b[39m=\u001b[39m layout_patch \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m   1994\u001b[0m apply_default_cascade(args)\n\u001b[0;32m-> 1996\u001b[0m args \u001b[39m=\u001b[39m build_dataframe(args, constructor)\n\u001b[1;32m   1997\u001b[0m \u001b[39mif\u001b[39;00m constructor \u001b[39min\u001b[39;00m [go\u001b[39m.\u001b[39mTreemap, go\u001b[39m.\u001b[39mSunburst, go\u001b[39m.\u001b[39mIcicle] \u001b[39mand\u001b[39;00m args[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1998\u001b[0m     args \u001b[39m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1409\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[0;34m(args, constructor)\u001b[0m\n\u001b[1;32m   1406\u001b[0m     args[\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m \u001b[39m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[0;32m-> 1409\u001b[0m df_output, wide_id_vars \u001b[39m=\u001b[39m process_args_into_dataframe(\n\u001b[1;32m   1410\u001b[0m     args, wide_mode, var_name, value_name\n\u001b[1;32m   1411\u001b[0m )\n\u001b[1;32m   1413\u001b[0m \u001b[39m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[39m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[39m# df_output\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m count_name \u001b[39m=\u001b[39m _escape_col_name(df_output, \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/plotly/express/_core.py:1208\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[0;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[39mif\u001b[39;00m argument \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1207\u001b[0m             err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m   1209\u001b[0m \u001b[39melif\u001b[39;00m length \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(df_input[argument]) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m   1210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1211\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll arguments should have the same length. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1212\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe length of column argument `df[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]` is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, whereas the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         )\n\u001b[1;32m   1220\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['SA2 Regions', 'Score'] but received: Average income"
     ]
    }
   ],
   "source": [
    "fig = px.scatter(df, x='Average income', y='Score', color='Average income')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94990b19",
   "metadata": {},
   "source": [
    "Table of all collected data, can be better seen by looking at Scores_data.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1b00b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2 Region</th>\n",
       "      <th>Retail Z-score</th>\n",
       "      <th>Health Z-score</th>\n",
       "      <th>Stops Z-score</th>\n",
       "      <th>Schools Z-score</th>\n",
       "      <th>Crashes Z-score</th>\n",
       "      <th>Crime Z-score</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Potts Point - Woolloomooloo</td>\n",
       "      <td>0.187257</td>\n",
       "      <td>0.218612</td>\n",
       "      <td>-1.049042</td>\n",
       "      <td>-0.435592</td>\n",
       "      <td>0.206298</td>\n",
       "      <td>12.029049</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redfern</td>\n",
       "      <td>-0.122362</td>\n",
       "      <td>-0.055329</td>\n",
       "      <td>-1.001798</td>\n",
       "      <td>0.416602</td>\n",
       "      <td>0.803806</td>\n",
       "      <td>3.923932</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parramatta - South</td>\n",
       "      <td>-0.054884</td>\n",
       "      <td>-0.536646</td>\n",
       "      <td>-1.119908</td>\n",
       "      <td>-1.074738</td>\n",
       "      <td>1.849446</td>\n",
       "      <td>-0.155904</td>\n",
       "      <td>0.005158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surry Hills</td>\n",
       "      <td>1.582215</td>\n",
       "      <td>1.599338</td>\n",
       "      <td>-1.108097</td>\n",
       "      <td>-0.009495</td>\n",
       "      <td>0.574762</td>\n",
       "      <td>6.933998</td>\n",
       "      <td>0.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pyrmont</td>\n",
       "      <td>0.403730</td>\n",
       "      <td>0.231247</td>\n",
       "      <td>-1.297074</td>\n",
       "      <td>-1.713884</td>\n",
       "      <td>-0.241833</td>\n",
       "      <td>1.103627</td>\n",
       "      <td>0.017634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chatswood - East</td>\n",
       "      <td>1.104709</td>\n",
       "      <td>2.192271</td>\n",
       "      <td>-0.115972</td>\n",
       "      <td>-0.009495</td>\n",
       "      <td>0.943225</td>\n",
       "      <td>-0.155904</td>\n",
       "      <td>0.994727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parramatta - North</td>\n",
       "      <td>1.318866</td>\n",
       "      <td>1.391161</td>\n",
       "      <td>-1.108097</td>\n",
       "      <td>0.629650</td>\n",
       "      <td>-0.062580</td>\n",
       "      <td>-0.155904</td>\n",
       "      <td>0.996954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baulkham Hills (West) - Bella Vista</td>\n",
       "      <td>0.598903</td>\n",
       "      <td>2.809188</td>\n",
       "      <td>1.939146</td>\n",
       "      <td>0.629650</td>\n",
       "      <td>0.285966</td>\n",
       "      <td>-0.155904</td>\n",
       "      <td>0.997611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dural - Kenthurst - Wisemans Ferry</td>\n",
       "      <td>0.311823</td>\n",
       "      <td>-0.155723</td>\n",
       "      <td>6.415522</td>\n",
       "      <td>4.890621</td>\n",
       "      <td>1.700069</td>\n",
       "      <td>-0.155904</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sydney (North) - Millers Point</td>\n",
       "      <td>17.018879</td>\n",
       "      <td>14.366576</td>\n",
       "      <td>0.297414</td>\n",
       "      <td>-0.435592</td>\n",
       "      <td>4.239478</td>\n",
       "      <td>9.128096</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SA2 Region  Retail Z-score  Health Z-score  \\\n",
       "0           Potts Point - Woolloomooloo        0.187257        0.218612   \n",
       "0                               Redfern       -0.122362       -0.055329   \n",
       "0                    Parramatta - South       -0.054884       -0.536646   \n",
       "0                           Surry Hills        1.582215        1.599338   \n",
       "0                               Pyrmont        0.403730        0.231247   \n",
       "..                                  ...             ...             ...   \n",
       "0                      Chatswood - East        1.104709        2.192271   \n",
       "0                    Parramatta - North        1.318866        1.391161   \n",
       "0   Baulkham Hills (West) - Bella Vista        0.598903        2.809188   \n",
       "0    Dural - Kenthurst - Wisemans Ferry        0.311823       -0.155723   \n",
       "0        Sydney (North) - Millers Point       17.018879       14.366576   \n",
       "\n",
       "    Stops Z-score  Schools Z-score  Crashes Z-score  Crime Z-score     Score  \n",
       "0       -1.049042        -0.435592         0.206298      12.029049  0.000003  \n",
       "0       -1.001798         0.416602         0.803806       3.923932  0.003055  \n",
       "0       -1.119908        -1.074738         1.849446      -0.155904  0.005158  \n",
       "0       -1.108097        -0.009495         0.574762       6.933998  0.006598  \n",
       "0       -1.297074        -1.713884        -0.241833       1.103627  0.017634  \n",
       "..            ...              ...              ...            ...       ...  \n",
       "0       -0.115972        -0.009495         0.943225      -0.155904  0.994727  \n",
       "0       -1.108097         0.629650        -0.062580      -0.155904  0.996954  \n",
       "0        1.939146         0.629650         0.285966      -0.155904  0.997611  \n",
       "0        6.415522         4.890621         1.700069      -0.155904  0.999985  \n",
       "0        0.297414        -0.435592         4.239478       9.128096  1.000000  \n",
       "\n",
       "[359 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['SA2 Region', 'Retail Z-score', 'Health Z-score', 'Stops Z-score', 'Schools Z-score', 'Crashes Z-score', 'Crime Z-score', 'Score'])\n",
    "for region in sorted_scores.keys():\n",
    "    row = [region, retail_zscores[region], health_zscores[region], stops_zscores[region], \n",
    "           schools_zscores[region], crash_zscores[region], crime_zscores[region], new_scores[region]]\n",
    "    row_df = pd.DataFrame([row], columns=df.columns)\n",
    "    df = pd.concat([df, row_df])\n",
    "  \n",
    "df.to_excel(\"Scores_data.xlsx\", index=False)  \n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df0e7415",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "From the table above, it can be seen that most of the regions have z-scores for all fields hovering around 0, which is to be expected. However there are immense outliers for the scores at the top and bottom, with Potts Point - Woolloomooloo having a really high Crime Z-score, which resulted in its low score, despite being average in the other categories. Interestingly, the top scoring region Sydney (North) - Millers Point also had a high Crime Z-score, however it was balanced by even higher Retail and Health Z-scores. This is a limitation of the model, as a region with such high crime rates maybe shouldn't be seen as the most \"well-resourced\" / best to live in region in the area.\n",
    "\n",
    "Outliers in general are a limitation of this model, as an area can be considered \"well-resourced\" with just a sufficient number of Retail businesses, Health services, etc. and sufficiently low Crash and Csrime rates. In order to improve this model, the effect of these outliers could be mitigated, or the data could be otherwise standardized.\n",
    "\n",
    "Furthermore, weighting could be added, where certain aspects such as Health services and Crime rate would be weighted higher than others.\n",
    "\n",
    "In conclusion, the most \"well-resourced\" by our scoring system is Sydney (North) - Millers Point, and the least is Potts Point - Woolloomooloo. Looking at the different aspects invidually, we can find which two regions are the best and worst for each resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2075319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Values:\n",
      "Retail Z-score     17.018879\n",
      "Health Z-score     14.366576\n",
      "Stops Z-score       6.415522\n",
      "Schools Z-score     4.890621\n",
      "Crashes Z-score     4.239478\n",
      "Crime Z-score      12.029049\n",
      "dtype: float64\n",
      "Min Values:\n",
      "Retail Z-score    -0.604961\n",
      "Health Z-score    -0.870939\n",
      "Stops Z-score     -1.675026\n",
      "Schools Z-score   -2.139981\n",
      "Crashes Z-score   -1.645977\n",
      "Crime Z-score     -0.155904\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "columns = ['Retail Z-score', 'Health Z-score', 'Stops Z-score', 'Schools Z-score', 'Crashes Z-score', 'Crime Z-score']\n",
    "\n",
    "max_values = df[columns].max()\n",
    "print(\"Max Values:\")\n",
    "print(max_values)\n",
    "min_values = df[columns].min()\n",
    "print(\"Min Values:\")\n",
    "print(min_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ed7018c",
   "metadata": {},
   "source": [
    "Using these values we get:\n",
    "- Retail: Most = Sydney (North) - Millers Point, Least = Narara\n",
    "- Health: Most = Sydney (North) - Millers Point, Least = Acacia Gardens\n",
    "- Stops: Most = Dural - Kenthurst - Wisemans Ferry, Least = Wolli Creek\n",
    "- Schools: Most = Dural - Kenthurst - Wisemans Ferry, Least = Summerland Point - Gwandalan\n",
    "- Crashes: Most = Sydney (North) - Millers Point, Least = Lilli Pilli - Port Hacking - Dolans Bay\n",
    "- Crime: Most = Potts Point - Woolloomooloo, Least = Many different regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
