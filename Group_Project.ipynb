{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1524a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ee0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = \"Credentials.json\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host       = db_conn_dict['host']\n",
    "        db_user    = db_conn_dict['user']\n",
    "        db_pw      = db_conn_dict['password']\n",
    "        default_db = db_conn_dict['user']\n",
    "        try:\n",
    "            db = create_engine('postgresql+psycopg2://'+db_user+':'+db_pw+'@'+host+'/'+default_db, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db,conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(sqlcmd, args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141738fb",
   "metadata": {},
   "source": [
    "Connect SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4f0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "source": [
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ca19f",
   "metadata": {},
   "source": [
    "Open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cb1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = gpd.read_file('SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp')\n",
    "businesses = pd.read_csv('Businesses.csv')\n",
    "stops = pd.read_csv('Stops.txt')\n",
    "polls = pd.read_csv('PollingPlaces2019.csv')\n",
    "school_future = gpd.read_file('catchments/catchments_future.shp')\n",
    "school_primary = gpd.read_file('catchments/catchments_primary.shp')\n",
    "school_secondary = gpd.read_file('catchments/catchments_secondary.shp')\n",
    "population = pd.read_csv('Population.csv')\n",
    "income = pd.read_csv('Income.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcd38a",
   "metadata": {},
   "source": [
    "Ensure every row in geometry is represented as multipolygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc13910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)\n",
    "\n",
    "srid = 4326\n",
    "regions.dropna(inplace=True)\n",
    "regions['geom'] = regions['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))  # applying the function\n",
    "regions = regions.drop(columns=\"geometry\")  # deleting the old copy\n",
    "\n",
    "school_future['geom'] = school_future['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_future = school_future.drop(columns=\"geometry\")\n",
    "\n",
    "school_primary['geom'] = school_primary['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_primary = school_primary.drop(columns=\"geometry\")\n",
    "\n",
    "school_secondary['geom'] = school_secondary['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))\n",
    "school_secondary = school_secondary.drop(columns=\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf458e2",
   "metadata": {},
   "source": [
    "Create a column 'geom' for stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e158113",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['geom'] = gpd.points_from_xy(stops.stop_lon, stops.stop_lat)\n",
    "stops = stops.drop(columns=['stop_lat', 'stop_lon'])\n",
    "stops['geom'] = stops['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee2bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "polls.dropna(subset=['the_geom'], inplace=True)\n",
    "polls['geom'] = gpd.points_from_xy(polls.longitude, polls.latitude)\n",
    "polls['geom'] = polls['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))\n",
    "polls.drop(columns=['the_geom'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92613098",
   "metadata": {},
   "source": [
    "Rename columns because some of the column names start with number or is uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dba7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_converter_regions(col_names):\n",
    "    col_dict = {}\n",
    "    for c in col_names:\n",
    "        new_c = c.lower() #convert every column name to lowercase\n",
    "        if new_c[-2:] == '21': # if column names end with 21, remove it\n",
    "            new_c = new_c[:-2]\n",
    "        if new_c == 'loci_uri':\n",
    "            new_c = 'url'\n",
    "        col_dict[c] = new_c\n",
    "    return col_dict\n",
    "\n",
    "def col_converter_school(col_names):\n",
    "    col_dict = {}\n",
    "    for c in col_names:\n",
    "        col_dict[c] = c.lower()\n",
    "    return col_dict\n",
    "\n",
    "col_names = regions.columns.values.tolist()\n",
    "regions = regions.rename(columns=col_converter_regions(col_names))\n",
    "\n",
    "col_names = school_future.columns.tolist()\n",
    "school_future = school_future.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "col_names = school_primary.columns.tolist()\n",
    "school_primary = school_primary.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "col_names = school_secondary.columns.tolist()\n",
    "school_secondary = school_secondary.rename(columns=col_converter_school(col_names))\n",
    "\n",
    "businesses = businesses.rename(columns={'0_to_50k_businesses':'b_0_to_50k', '50k_to_200k_businesses':'b_50k_to_200k', '200k_to_2m_businesses':'b_200k_to_2m'})\n",
    "businesses = businesses.rename(columns={'2m_to_5m_businesses':'b_2m_to_5m', '5m_to_10m_businesses':'b_5m_to_10m', '10m_or_more_businesses':'b_10m_or_more'})\n",
    "\n",
    "population = population.rename(columns={'0-4_people':'p_0_to_4', '5-9_people':'p_5_to_9', '10-14_people':'p_10_to_14', '15-19_people':'p_15_to_19'})\n",
    "population = population.rename(columns={'20-24_people':'p_20_to_24', '25-29_people':'p_25_to_29', '30-34_people':'p_30_to_34', '35-39_people':'p_35_to_39'})\n",
    "population = population.rename(columns={'40-44_people':'p_40_to_44', '45-49_people':'p_45_to_49', '50-54_people':'p_50_to_54', '55-59_people':'p_55_to_59'})\n",
    "population = population.rename(columns={'60-64_people':'p_60_to_64', '65-69_people':'p_65_to_69', '70-74_people':'p_70_to_74', '75-79_people':'p_75_to_79'})\n",
    "population = population.rename(columns={'80-84_people':'p_80_to_84', '85-and-over_people':'p_85_and_over'})\n",
    "\n",
    "polls = polls.rename(columns={'FID':'fid'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eea7c6",
   "metadata": {},
   "source": [
    "Replace some NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b36aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.replace('np', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac9243",
   "metadata": {},
   "source": [
    "Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcdf12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1843be04fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS regions cascade;\n",
    "CREATE TABLE regions (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    chg_flag CHAR,\n",
    "    chg_lbl VARCHAR(20),\n",
    "    sa3_code VARCHAR(5),\n",
    "    sa3_name VARCHAR(100),\n",
    "    sa4_code VARCHAR(3),\n",
    "    sa4_name VARCHAR(100),\n",
    "    gcc_code VARCHAR(5),\n",
    "    gcc_name VARCHAR(100),\n",
    "    ste_code CHAR,\n",
    "    ste_name VARCHAR(100),\n",
    "    aus_code VARCHAR(3),\n",
    "    aus_name VARCHAR(100),\n",
    "    areasqkm FLOAT,\n",
    "    url VARCHAR(100),\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS businesses;\n",
    "CREATE TABLE businesses (\n",
    "    industry_code CHAR, \n",
    "    industry_name VARCHAR(100),\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    b_0_to_50k INTEGER,\n",
    "    b_50k_to_200k INTEGER,\n",
    "    b_200k_to_2m INTEGER,\n",
    "    b_2m_to_5m INTEGER,\n",
    "    b_5m_to_10m INTEGER,\n",
    "    b_10m_or_more INTEGER,\n",
    "    total_businesses INTEGER\n",
    ");\n",
    "\"\"\"))\n",
    "#b_0_to_50k is the number of businesses' income < 50k\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS stops;\n",
    "CREATE TABLE stops (\n",
    "    stop_id VARCHAR(10),\n",
    "    stop_code VARCHAR(10),\n",
    "    stop_name VARCHAR(100),\n",
    "    location_type FLOAT,\n",
    "    parent_station VARCHAR(10),\n",
    "    wheelchair_boarding CHAR,\n",
    "    platform_code VARCHAR(10),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS polls;\n",
    "CREATE TABLE polls (\n",
    "    fid VARCHAR(100),\n",
    "    state VARCHAR(3),\n",
    "    division_id INTEGER,\n",
    "    division_name VARCHAR(100),\n",
    "    polling_place_id INTEGER,\n",
    "    polling_place_type_id INTEGER,\n",
    "    polling_place_name VARCHAR(100),\n",
    "    premises_name VARCHAR(100),\n",
    "    premises_address_1 VARCHAR(100),\n",
    "    premises_address_2 VARCHAR(100),\n",
    "    premises_address_3 VARCHAR(100),\n",
    "    premises_suburb VARCHAR(100),\n",
    "    premises_state_abbreviation VARCHAR(3),\n",
    "    premises_post_code INTEGER,\n",
    "    latitude FLOAT,\n",
    "    longitude FLOAT,\n",
    "    geom GEOMETRY(POINT,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_future;\n",
    "CREATE TABLE school_future (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart INTEGER,\n",
    "    year1 INTEGER,\n",
    "    year2 INTEGER,\n",
    "    year3 INTEGER,\n",
    "    year4 INTEGER,\n",
    "    year5 INTEGER,\n",
    "    year6 INTEGER,\n",
    "    year7 INTEGER,\n",
    "    year8 INTEGER,\n",
    "    year9 INTEGER,\n",
    "    year10 INTEGER,\n",
    "    year11 INTEGER,\n",
    "    year12 INTEGER,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_primary;\n",
    "CREATE TABLE school_primary (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart CHAR,\n",
    "    year1 CHAR,\n",
    "    year2 CHAR,\n",
    "    year3 CHAR,\n",
    "    year4 CHAR,\n",
    "    year5 CHAR,\n",
    "    year6 CHAR,\n",
    "    year7 CHAR,\n",
    "    year8 CHAR,\n",
    "    year9 CHAR,\n",
    "    year10 CHAR,\n",
    "    year11 CHAR,\n",
    "    year12 CHAR,\n",
    "    priority CHAR,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS school_secondary;\n",
    "CREATE TABLE school_secondary (\n",
    "    use_id VARCHAR(4),\n",
    "    catch_type VARCHAR(20),\n",
    "    use_desc VARCHAR(100),\n",
    "    add_date INTEGER,\n",
    "    kindergart CHAR,\n",
    "    year1 CHAR,\n",
    "    year2 CHAR,\n",
    "    year3 CHAR,\n",
    "    year4 CHAR,\n",
    "    year5 CHAR,\n",
    "    year6 CHAR,\n",
    "    year7 CHAR,\n",
    "    year8 CHAR,\n",
    "    year9 CHAR,\n",
    "    year10 CHAR,\n",
    "    year11 CHAR,\n",
    "    year12 CHAR,\n",
    "    priority CHAR,\n",
    "    geom GEOMETRY(MULTIPOLYGON,4326)\n",
    ");\n",
    "\"\"\"))\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS population;\n",
    "CREATE TABLE population (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    p_0_to_4 INTEGER,\n",
    "    p_5_to_9 INTEGER,\n",
    "    p_10_to_14 INTEGER,\n",
    "    p_15_to_19 INTEGER,\n",
    "    p_20_to_24 INTEGER,\n",
    "    p_25_to_29 INTEGER,\n",
    "    p_30_to_34 INTEGER,\n",
    "    p_35_to_39 INTEGER,\n",
    "    p_40_to_44 INTEGER,\n",
    "    p_45_to_49 INTEGER,\n",
    "    p_50_to_54 INTEGER,\n",
    "    p_55_to_59 INTEGER,\n",
    "    p_60_to_64 INTEGER,\n",
    "    p_65_to_69 INTEGER,\n",
    "    p_70_to_74 INTEGER,\n",
    "    p_75_to_79 INTEGER,\n",
    "    p_80_to_84 INTEGER,\n",
    "    p_85_and_over INTEGER,\n",
    "    total_people INTEGER\n",
    ");\n",
    "\"\"\"))\n",
    "#p_0_to_4 is the number of people age from 0 to 4\n",
    "\n",
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS income;\n",
    "CREATE TABLE income (\n",
    "    sa2_code VARCHAR(9),\n",
    "    sa2_name VARCHAR(100),\n",
    "    earners INTEGER,\n",
    "    median_age INTEGER,\n",
    "    median_income INTEGER,\n",
    "    mean_income INTEGER\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c973e0f",
   "metadata": {},
   "source": [
    "Importing dataframes to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376a0842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regions.to_sql('regions', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "businesses.to_sql('businesses', conn, if_exists='append', index=False)\n",
    "stops.to_sql('stops', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "polls.to_sql('polls', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "school_future.to_sql('school_future', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "school_primary.to_sql('school_primary', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "school_secondary.to_sql('school_secondary', conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "population.to_sql('population', conn, if_exists='append', index=False)\n",
    "income.to_sql('income', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab308fd",
   "metadata": {},
   "source": [
    "Get investigatable regions, young people per region, total people per region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb87a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, (p_0_to_4 + p_5_to_9 + p_10_to_14 + p_15_to_19) as young_people, total_people\n",
    "    FROM population\n",
    "\"\"\"))\n",
    "\n",
    "regions_arr = []\n",
    "region_to_young = dict()\n",
    "region_to_people = dict()\n",
    "for i, row in result.iterrows():\n",
    "    name, young, total = row.values\n",
    "    if young > 100 and total > 100:\n",
    "        regions_arr.append(name)\n",
    "        try:\n",
    "            young = int(young)\n",
    "            if young != 0:\n",
    "                region_to_young[name] = young\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "        try:\n",
    "            total = int(total)\n",
    "            if total != 0:\n",
    "                region_to_people[name] = total\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "\n",
    "print(len(regions_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e954aa",
   "metadata": {},
   "source": [
    "Retail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649391a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, total_businesses\n",
    "    FROM businesses\n",
    "    WHERE industry_name = 'Retail Trade'\n",
    "    ORDER BY total_businesses DESC\n",
    "\"\"\"))\n",
    "\n",
    "retail_dict = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    name, total = row.values\n",
    "    total = int(total)\n",
    "    retail_dict[name] = total\n",
    "\n",
    "retail_per_thousand = dict.fromkeys(regions_arr, 0)\n",
    "for key in retail_dict.keys():\n",
    "    try:\n",
    "        num = (retail_dict[key] / region_to_people[key])*1000\n",
    "        retail_per_thousand[key] = num\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "retail_per_thousand = dict(sorted(retail_per_thousand.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "zscores = zscore(list(retail_per_thousand.values()))\n",
    "retail_zscores = dict(zip(retail_per_thousand.keys(), zscores))\n",
    "\n",
    "print(len(retail_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f8dc5",
   "metadata": {},
   "source": [
    "Health:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc7c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\" \n",
    "    SELECT sa2_name, total_businesses\n",
    "    FROM businesses\n",
    "    WHERE industry_name = 'Health Care and Social Assistance'\n",
    "    ORDER BY total_businesses DESC\n",
    "\"\"\"))\n",
    "\n",
    "health_dict = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    name, total = row.values\n",
    "    total = int(total)\n",
    "    health_dict[name] = total\n",
    "\n",
    "health_per_thousand = dict()\n",
    "for key in health_dict.keys():\n",
    "    try:\n",
    "        num = (health_dict[key] / region_to_people[key])*1000\n",
    "        health_per_thousand[key] = num\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "health_per_thousand = dict(sorted(health_per_thousand.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "zscores = zscore(list(health_per_thousand.values()))\n",
    "health_zscores = dict(zip(health_per_thousand.keys(), zscores))\n",
    "    \n",
    "print(len(health_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3be005",
   "metadata": {},
   "source": [
    "Index regions and stops for fast JOIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d58898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_regions;\n",
    "    CREATE INDEX geom_idx_regions ON regions USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_stops;\n",
    "    CREATE INDEX geom_idx_stops ON regions USING GIST(geom);\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39bfeb",
   "metadata": {},
   "source": [
    "Stops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "027fccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN stops s ON ST_Contains(r.geom, s.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "stops_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        stops_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(stops_per_region.values()))\n",
    "stops_zscores = dict(zip(stops_per_region.keys(), zscores))\n",
    "\n",
    "print(len(stops_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b352c",
   "metadata": {},
   "source": [
    "Polls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2857b2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "# This doesn't seem right -> it doesn't have the subdivisions of sa2 but ST_Contains isn't returning anything\n",
    "\n",
    "# result = query(conn, text(\"\"\"\n",
    "#     SELECT r.sa2_name, COUNT(*) FROM polls p\n",
    "#     JOIN regions r on p.division_name = r.sa2_name\n",
    "#     GROUP BY r.sa2_name\n",
    "#     ORDER BY count DESC\n",
    "# \"\"\"))\n",
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN polls p ON ST_Contains(r.geom, p.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "polls_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        polls_per_region[region] = count\n",
    "\n",
    "zscores = zscore(list(polls_per_region.values()))\n",
    "polls_zscores = dict(zip(polls_per_region.keys(), zscores))\n",
    "\n",
    "print(len(polls_zscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "431cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_primary;\n",
    "    CREATE INDEX geom_idx_primary ON school_primary USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_secondary;\n",
    "    CREATE INDEX geom_idx_secondary ON school_secondary USING GIST(geom);\n",
    "\"\"\"));\n",
    "conn.execute(text(\"\"\"\n",
    "    DROP INDEX IF EXISTS geom_idx_future;\n",
    "    CREATE INDEX geom_idx_future ON school_future USING GIST(geom);\n",
    "\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ac8ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_primary s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "schools_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] = count\n",
    "\n",
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_secondary s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] += count\n",
    "\n",
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*)\n",
    "    FROM regions r\n",
    "        JOIN school_future s ON ST_Intersects(r.geom, s.geom)\n",
    "    GROUP BY sa2_name\n",
    "    ORDER BY count DESC\n",
    "\"\"\"))\n",
    "\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        schools_per_region[region] += count\n",
    "        \n",
    "zscores = zscore(list(schools_per_region.values()))\n",
    "schools_zscores = dict(zip(schools_per_region.keys(), zscores))\n",
    "\n",
    "print(len(schools_zscores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd8198",
   "metadata": {},
   "source": [
    "Calculate Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e508d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "for region in regions_arr:\n",
    "    sum = 0\n",
    "    try:\n",
    "        sum += retail_zscores.get(region)\n",
    "        sum += health_zscores.get(region)\n",
    "        sum += stops_zscores.get(region)\n",
    "        sum += polls_zscores.get(region)\n",
    "        sum += schools_zscores.get(region)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    scores[region] = 1 / (1 + math.exp(-sum))\n",
    "\n",
    "print(len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429d9b0",
   "metadata": {},
   "source": [
    "End result is: Score = Sigmoid(z_retail + z_health + z_stops + z_polls + z_schools)\n",
    "\n",
    "Need to find:\n",
    "- Regions\n",
    "- Number of retail, health, stops, polls, schools per region\n",
    "- Average for each field\n",
    "- z score for each field for each region\n",
    "- Sigmoid for each region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d29ec",
   "metadata": {},
   "source": [
    "Car crash in NSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e23c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = pd.read_excel('car_crash.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f3cb3",
   "metadata": {},
   "source": [
    "Kepp specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56e4513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash = crash[['Degree of crash', 'Year of crash', 'Month of crash', 'Day of week of crash', 'Latitude', 'Longitude', 'Weather']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d0e03",
   "metadata": {},
   "source": [
    "Create geom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f184e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash.dropna(inplace=True)\n",
    "crash['geom'] = gpd.points_from_xy(crash.Longitude, crash.Latitude)\n",
    "crash = crash.drop(columns=['Longitude', 'Latitude'])\n",
    "crash['geom'] = crash['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19693bc3",
   "metadata": {},
   "source": [
    "Convert columns to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a31a47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weather</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>POINT (153.177111 -30.139448)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>POINT (150.900204 -32.793739)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (146.24477 -34.504211)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>POINT (150.906729 -33.746029)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (150.096208 -36.295248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101713</th>\n",
       "      <td>Injury</td>\n",
       "      <td>2021</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (151.373795 -33.507164)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101714</th>\n",
       "      <td>Injury</td>\n",
       "      <td>2021</td>\n",
       "      <td>July</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (150.816772 -33.971615)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101715</th>\n",
       "      <td>Non-casualty (towaway)</td>\n",
       "      <td>2021</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>POINT (151.66334 -32.889647)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101716</th>\n",
       "      <td>Non-casualty (towaway)</td>\n",
       "      <td>2021</td>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (151.164528 -33.727898)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101717</th>\n",
       "      <td>Fatal</td>\n",
       "      <td>2021</td>\n",
       "      <td>October</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Fine</td>\n",
       "      <td>POINT (149.586884 -32.590801)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101718 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        degree  year     month       day   weather  \\\n",
       "0                        Fatal  2017   January    Monday  Overcast   \n",
       "1                        Fatal  2017   January    Monday  Overcast   \n",
       "2                        Fatal  2017   January   Tuesday      Fine   \n",
       "3                        Fatal  2017   January  Thursday  Overcast   \n",
       "4                        Fatal  2017   January  Saturday      Fine   \n",
       "...                        ...   ...       ...       ...       ...   \n",
       "101713                  Injury  2021       May   Tuesday      Fine   \n",
       "101714                  Injury  2021      July  Saturday      Fine   \n",
       "101715  Non-casualty (towaway)  2021  February   Tuesday  Overcast   \n",
       "101716  Non-casualty (towaway)  2021  November    Monday      Fine   \n",
       "101717                   Fatal  2021   October  Saturday      Fine   \n",
       "\n",
       "                                 geom  \n",
       "0       POINT (153.177111 -30.139448)  \n",
       "1       POINT (150.900204 -32.793739)  \n",
       "2        POINT (146.24477 -34.504211)  \n",
       "3       POINT (150.906729 -33.746029)  \n",
       "4       POINT (150.096208 -36.295248)  \n",
       "...                               ...  \n",
       "101713  POINT (151.373795 -33.507164)  \n",
       "101714  POINT (150.816772 -33.971615)  \n",
       "101715   POINT (151.66334 -32.889647)  \n",
       "101716  POINT (151.164528 -33.727898)  \n",
       "101717  POINT (149.586884 -32.590801)  \n",
       "\n",
       "[101718 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dict = {}\n",
    "for c in crash.columns:\n",
    "    col_dict[c] = c.lower()\n",
    "    keyword = c.split(' ')[0]\n",
    "    if keyword in ['Degree', 'Year', 'Month', 'Day']:\n",
    "        col_dict[c] = keyword.lower()\n",
    "crash.rename(columns=col_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce94e2b",
   "metadata": {},
   "source": [
    "Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22acb890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x18476e51eb0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS crash;\n",
    "CREATE TABLE crash (\n",
    "    degree VARCHAR(100),\n",
    "    year INT,\n",
    "    month VARCHAR(20),\n",
    "    day VARCHAR(15),\n",
    "    weather VARCHAR(50),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c90a8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash.to_sql('crash', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1529df48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN crash c ON ST_Contains(r.geom, c.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count(*) DESC\n",
    "\"\"\"))\n",
    "\n",
    "crash_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        crash_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(crash_per_region.values()))\n",
    "crash_zscores = dict(zip(crash_per_region.keys(), zscores))\n",
    "print(len(crash_zscores))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83975975",
   "metadata": {},
   "source": [
    "Crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "eb0de58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = pd.read_csv(\"crime_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427d590",
   "metadata": {},
   "source": [
    "Keep specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d204a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = crime[['bcsrgrp', 'locsurb', 'locpcode', 'bcsrgclat', 'bcsrgclng', 'incyear', 'incmonth', 'incday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75ab83",
   "metadata": {},
   "source": [
    "Create geom column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "19dc7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.dropna(subset=['bcsrgclat', 'bcsrgclng'], inplace=True)\n",
    "crime['geom'] = gpd.points_from_xy(crime.bcsrgclng, crime.bcsrgclat)\n",
    "crime = crime.drop(columns=['bcsrgclng', 'bcsrgclat'])\n",
    "crime['geom'] = crime['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309dc643",
   "metadata": {},
   "source": [
    "Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "14c7febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1840aeb0a00>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(text(\"\"\"\n",
    "DROP TABLE IF EXISTS crime;\n",
    "CREATE TABLE crime (\n",
    "    bcsrgrp VARCHAR(100),\n",
    "    locsurb VARCHAR(100), \n",
    "    locpcode INT,\n",
    "    incyear INT,\n",
    "    incmonth VARCHAR(15),\n",
    "    incday VARCHAR(10),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b5cc15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.to_sql('crime', conn, if_exists='append', index=False, dtype={'geom': Geometry('POINT', srid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "02167ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "result = query(conn, text(\"\"\"\n",
    "    SELECT r.sa2_name, COUNT(*) \n",
    "    FROM regions r\n",
    "        JOIN crime c ON ST_Contains(r.geom, c.geom)\n",
    "    GROUP BY r.sa2_name\n",
    "    ORDER BY count(*) DESC\n",
    "\"\"\"))\n",
    "\n",
    "crime_per_region = dict.fromkeys(regions_arr, 0)\n",
    "for i, row in result.iterrows():\n",
    "    region, count = row.values\n",
    "    if region in regions_arr:\n",
    "        crime_per_region[region] = count\n",
    "    \n",
    "zscores = zscore(list(crime_per_region.values()))\n",
    "crime_zscores = dict(zip(crime_per_region.keys(), zscores))\n",
    "print(len(crime_zscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e155d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
